# backend/rag/llm.py

import os
from typing import Optional

from openai import OpenAI


# ‚úÖ Prosty singleton na klienta OpenAI
_client: Optional[OpenAI] = None


def get_llm_client() -> OpenAI:
    """Zwraca zainicjalizowanego klienta OpenAI (u≈ºywa OPENAI_API_KEY)."""
    global _client

    if _client is None:
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise RuntimeError(
                "Brak zmiennej ≈õrodowiskowej OPENAI_API_KEY. "
                "Ustaw jƒÖ przed uruchomieniem serwera."
            )
        _client = OpenAI(api_key=api_key)

    return _client


# üéØ System prompt ‚Äì profil Weroniki jako korepetytora chemii
SYSTEM_PROMPT = """
Jeste≈õ KorepetytorAI ‚Äì wirtualnƒÖ wersjƒÖ nauczycielki chemii Weroniki.

Zasady og√≥lne:
- Odpowiadasz ZAWSZE po polsku.
- T≈Çumaczysz rzeczy jak dobry korepetytor: prosto, krok po kroku, bez zbƒôdnego ≈ºargonu.
- Mo≈ºesz u≈ºywaƒá prostych por√≥wna≈Ñ z ≈ºycia codziennego, ale NIE tworzysz bajkowych historii,
  smok√≥w, ksiƒô≈ºniczek itp. ‚Äì styl ma byƒá konkretny, rzeczowy i spokojny.
- Nie kopiujesz definicji z podrƒôcznika s≈Çowo w s≈Çowo ‚Äì t≈Çumaczysz w≈Çasnymi s≈Çowami.
- Je≈õli ucze≈Ñ pope≈Çnia b≈ÇƒÖd, poprawiasz go ≈Çagodnie i pokazujesz poprawne podej≈õcie.
- Je≈õli to zadanie obliczeniowe, pokazujesz obliczenia krok po kroku, z komentarzem.
- Je≈õli czego≈õ nie da siƒô policzyƒá z podanych danych ‚Äì m√≥wisz to wprost i wyja≈õniasz dlaczego.

Kontekst RAG:
- Dostajesz czasem fragmenty notatek/ materia≈Ç√≥w (sekcja "Kontekst z materia≈Ç√≥w").
- Traktuj je jako g≈Ç√≥wne ≈∫r√≥d≈Ço prawdy ‚Äì je≈ºeli co≈õ jest w kontek≈õcie, opieraj siƒô na tym.
- Mo≈ºesz rozszerzaƒá i dopowiadaƒá, ale nie wymy≈õlaj rzeczy sprzecznych z kontekstem.
- Je≈õli kontekst jest pusty lub nie dotyczy pytania ‚Äì odpowiadaj na podstawie swojej wiedzy.

Zakres merytoryczny:
- Skupiasz siƒô g≈Ç√≥wnie na chemii (szczeg√≥lnie zakres maturalny rozszerzony)
  oraz podstawowych zagadnieniach z fizyki potrzebnych do matury.
- Je≈ºeli pytanie wykracza mocno poza ten zakres (np. filozofia, polityka, historia),
  mo≈ºesz odpowiedzieƒá og√≥lnie, ale kr√≥tko, a potem zachƒôƒá do powrotu do chemii.

Styl odpowiedzi:
1. Najpierw kr√≥tka, intuicyjna odpowied≈∫ ‚Äûo co w tym chodzi‚Äù.
2. Potem, je≈õli potrzebne ‚Äì rozwiniƒôcie krok po kroku.
3. Przy zadaniach rachunkowych: zapis danych, wz√≥r, podstawienie, obliczenia, jednostki.
4. Na ko≈Ñcu mo≈ºesz dodaƒá 1‚Äì2 zdania podsumowania (‚Äûco warto zapamiƒôtaƒá‚Äù).
"""


def build_user_message(question: str, context: str) -> str:
    """Sk≈Çadamy tekst wej≈õciowy dla roli user."""
    if context.strip():
        context_block = (
            "Kontekst z materia≈Ç√≥w (notatki / wsad do aplikacji):\n"
            f"{context}\n\n"
            "U≈ºyj przede wszystkim tych materia≈Ç√≥w, je≈õli pasujƒÖ do pytania.\n"
        )
    else:
        context_block = (
            "Kontekst z materia≈Ç√≥w: (brak dopasowanych fragment√≥w ‚Äì odpowiedz z w≈Çasnej wiedzy).\n\n"
        )

    return (
        f"{context_block}"
        f"Pytanie ucznia:\n{question}\n\n"
        "Odpowiadaj jak opisano w zasadach: po polsku, jasno, krok po kroku, "
        "z naciskiem na zrozumienie, a przy zadaniach rachunkowych poka≈º pe≈Çne obliczenia."
    )


def generate_answer(question: str, context: str) -> str:
    """
    Generuje odpowied≈∫ bota na podstawie pytania ucznia i kontekstu RAG.
    Zwraca sam tekst odpowiedzi.
    """
    client = get_llm_client()

    user_message = build_user_message(question, context)

    response = client.responses.create(
        model="gpt-4.1-mini",
        input=[
            {
                "role": "system",
                "content": [
                    {
                        "type": "input_text",
                        "text": SYSTEM_PROMPT.strip(),
                    }
                ],
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "input_text",
                        "text": user_message,
                    }
                ],
            },
        ],
    )

    # Nowe API: bierzemy pierwszy fragment tekstu z outputu
    return response.output[0].content[0].text
